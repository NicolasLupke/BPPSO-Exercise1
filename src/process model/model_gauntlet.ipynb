{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d93c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c0a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\Desktop\\Repos\\BPPSO - Assignment 1\\pm4py\\pm4py\\utils.py:987: UserWarning: In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\n",
      "  warnings.warn(\"In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\")\n"
     ]
    }
   ],
   "source": [
    "log = pm4py.read_xes(\"..\\..\\Dataset\\BPI Challenge 2017.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f28432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = pm4py.read_bpmn(\"Process Models\\Process Model v7.bpmn\")\n", #Loop based Model
    "model16 = pm4py.read_bpmn(\"Process Models\\Process Model v16.bpmn\")\n", #Final Model
    "model17 = pm4py.read_bpmn(\"Process Models\\Process Model v17.bpmn\")" #Model with endpoints
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c7ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "petri_nets = [\n",
    "    (\"v7\",*pm4py.convert_to_petri_net(model7)),\n",
    "    (\"v16\",*pm4py.convert_to_petri_net(model16)),\n",
    "    (\"v17\",*pm4py.convert_to_petri_net(model17))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2d0081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pm4py import conformance_diagnostics_alignments\\n\\n\\nname,net,initial_marking, final_marking = petri_nets[0]\\nalign_results = conformance_diagnostics_alignments(log, net, initial_marking, final_marking)\\nprint(str(align_results))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from pm4py import conformance_diagnostics_alignments\n",
    "\n",
    "\n",
    "name,net,initial_marking, final_marking = petri_nets[0]\n",
    "align_results = conformance_diagnostics_alignments(log, net, initial_marking, final_marking)\n",
    "print(str(align_results))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b750bf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- v7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\Desktop\\Repos\\BPPSO - Assignment 1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:17<00:00, 205.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 26.163953156241075\n",
      "  average_trace_fitness: 0.9687952658381422\n",
      "  log_fitness: 0.9716910658926539\n",
      "  percentage_of_fitting_traces: 26.163953156241075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [08:07<00:00, 541.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.535241684446598\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.6538\n",
      "  entropy: 0.5186\n",
      "  simplicity_entropy: 0.9044\n",
      "  simplicity_size: 154.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [02:44<00:00, 96.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9929\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- v16 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [02:47<00:00, 95.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.8603715803992916\n",
      "  log_fitness: 0.8823063368294377\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [05:39<00:00, 778.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.9014254796131032\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.7204\n",
      "  entropy: 0.3444\n",
      "  simplicity_entropy: 0.9348\n",
      "  simplicity_size: 147.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [02:42<00:00, 97.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9672\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- v17 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [02:50<00:00, 93.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.8458864874170366\n",
      "  log_fitness: 0.8758076665615339\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [05:42<00:00, 771.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.9014254796131032\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.7087\n",
      "  entropy: 0.3376\n",
      "  simplicity_entropy: 0.9378\n",
      "  simplicity_size: 161.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [02:52<00:00, 92.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9443\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pm4py\n",
    "import traceback\n",
    "import math\n",
    "from simplicity_metrics import entropy_simplicity_petri_net, size_simplicity_metric\n",
    "\n",
    "for name, net, im, fm in petri_nets:\n",
    "    print(f\"--- {name} ---\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Token-based replay fitness\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        tbr_fitness = pm4py.fitness_token_based_replay(log, net, im, fm)\n",
    "        print(\"Token-based replay fitness:\")\n",
    "        for k, v in tbr_fitness.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing token-based replay fitness:\")\n",
    "        traceback.print_exc()\n",
    "        tbr_fitness = {}\n",
    "\n",
    "    # ----------------------------\n",
    "    # Alignment-based fitness\n",
    "    # ----------------------------\n",
    "    \"\"\"try:\n",
    "        align_fitness = pm4py.fitness_alignments(log, net, im, fm)\n",
    "        print(\"\\nAlignment-based fitness:\")\n",
    "        for k, v in align_fitness.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing alignment-based fitness:\")\n",
    "        traceback.print_exc()\n",
    "        align_fitness = {}\"\"\"\n",
    "    # ----------------------------\n",
    "    # Token-based replay precision\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        tbr_precision = pm4py.precision_token_based_replay(log, net, im, fm)\n",
    "        print(\"\\nToken-based replay precision:\")\n",
    "        print(f\"  precision: {tbr_precision}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing token-based replay precision:\")\n",
    "        traceback.print_exc()\n",
    "        tbr_precision = math.nan\n",
    "\n",
    "    # ----------------------------\n",
    "    # Alignment-based precision\n",
    "    # ----------------------------\n",
    "    \"\"\"try:\n",
    "        align_precision = pm4py.precision_alignments(log, net, im, fm)\n",
    "        print(\"\\nAlignment-based precision:\")\n",
    "        print(f\"  precision: {align_precision}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing alignment-based precision:\")\n",
    "        traceback.print_exc()\n",
    "        align_precision = math.nan\"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # Simplicity metrics\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        simplicity_arc = pm4py.simplicity_petri_net(net, im, fm, variant=\"arc_degree\")\n",
    "    except Exception:\n",
    "        print(\"Error computing arc-degree simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_arc = math.nan\n",
    "\n",
    "    \"\"\"try:\n",
    "        simplicity_cardoso = pm4py.simplicity_petri_net(net, im, fm, variant=\"extended_cardoso\")\n",
    "    except Exception:\n",
    "        print(\"Error computing Cardoso simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_cardoso = math.nan\n",
    "\n",
    "    try:\n",
    "        simplicity_cyclomatic = pm4py.simplicity_petri_net(net, im, fm, variant=\"extended_cyclomatic\")\n",
    "    except Exception:\n",
    "        print(\"Error computing Cyclomatic simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_cyclomatic = math.nan\"\"\"\n",
    "\n",
    "    try:\n",
    "        simplicity_entropy = entropy_simplicity_petri_net(net)\n",
    "    except Exception:\n",
    "        print(\"Error computing entropy-based simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_entropy = {'entropy': math.nan, 'simplicity': math.nan}\n",
    "\n",
    "    try:\n",
    "        simplicity_size = size_simplicity_metric(net)\n",
    "    except Exception:\n",
    "        print(\"Error computing size-based simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_size = math.nan\n",
    "\n",
    "    print(\"\\nSimplicity:\")\n",
    "    print(f\"  simplicity_arc_degree: {simplicity_arc:.4f}\" if isinstance(simplicity_arc, (float, int)) else f\"  simplicity_arc_degree: {simplicity_arc}\")\n",
    "    #print(f\"  simplicity_cardoso: {simplicity_cardoso:.4f}\" if isinstance(simplicity_cardoso, (float, int)) else f\"  simplicity_cardoso: {simplicity_cardoso}\")\n",
    "    #print(f\"  simplicity_cyclomatic: {simplicity_cyclomatic:.4f}\" if isinstance(simplicity_cyclomatic, (float, int)) else f\"  simplicity_cyclomatic: {simplicity_cyclomatic}\")\n",
    "    print(f\"  entropy: {simplicity_entropy['entropy']:.4f}\")\n",
    "    print(f\"  simplicity_entropy: {simplicity_entropy['simplicity']:.4f}\")\n",
    "    print(f\"  simplicity_size: {simplicity_size:.4f}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Generalization\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        generalization = pm4py.generalization_tbr(log, net, im, fm)\n",
    "        print(\"\\nGeneralization:\")\n",
    "        print(f\"  generalization: {generalization:.4f}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing generalization:\")\n",
    "        traceback.print_exc()\n",
    "        generalization = math.nan\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
