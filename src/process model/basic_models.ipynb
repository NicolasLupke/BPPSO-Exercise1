{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24892bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b7c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\Desktop\\Repos\\BPPSO - Assignment 1\\pm4py\\pm4py\\utils.py:987: UserWarning: In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\n",
      "  warnings.warn(\"In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\")\n"
     ]
    }
   ],
   "source": [
    "log = pm4py.read_xes(\"..\\..\\Dataset\\BPI Challenge 2017.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124ff606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_log = filter_log(log)\n",
    "#len(filtered_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc0c1a",
   "metadata": {},
   "source": [
    "cd \"X-Processes\\IS 2023 version\"; py xprocesses.py -log \"..\\..\\Dataset\\BPI Challenge 2017.xes\" -isl 4 -rnd 5 -gen 500 -tme 3600 -con 25 -fit 1 -prc 1 -gnl 1 -smp 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5364f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inductive Miner\n",
    "inductive_model = pm4py.discover_petri_net_inductive(log)\n",
    "\n",
    "# Alpha Miner\n",
    "alpha_model = pm4py.discover_petri_net_alpha(log)\n",
    "\n",
    "# Heuristic Miner (standard)\n",
    "heuristic_model1 = pm4py.discover_petri_net_heuristics(\n",
    "    log,\n",
    "    dependency_threshold=0.5,\n",
    "    and_threshold=0.65,\n",
    "    loop_two_threshold=0.5\n",
    ")\n",
    "\n",
    "# Heuristic Miner (stricter dependency filter)\n",
    "heuristic_model2 = pm4py.discover_petri_net_heuristics(\n",
    "    log,\n",
    "    dependency_threshold=0.9,\n",
    "    and_threshold=0.65,\n",
    "    loop_two_threshold=0.5,\n",
    ")\n",
    "\n",
    "# Balanced dependency vs. parallelism\n",
    "heuristic_model3 = pm4py.discover_petri_net_heuristics(\n",
    "    log,\n",
    "    dependency_threshold=0.7,\n",
    "    and_threshold=0.7,\n",
    "    loop_two_threshold=0.6\n",
    ")\n",
    "\n",
    "# Permissive, keeps more weak dependencies\n",
    "heuristic_model4 = pm4py.discover_petri_net_heuristics(\n",
    "    log,\n",
    "    dependency_threshold=0.4,\n",
    "    and_threshold=0.6,\n",
    "    loop_two_threshold=0.4,\n",
    ")\n",
    "\n",
    "# Highly selective\n",
    "heuristic_model5 = pm4py.discover_petri_net_heuristics(\n",
    "    log,\n",
    "    dependency_threshold=0.85,\n",
    "    and_threshold=0.8,\n",
    "    loop_two_threshold=0.7\n",
    ")\n",
    "\n",
    "model7 = pm4py.read_bpmn(\"Process Models\\Process Model v7.bpmn\")\n",
    "model16 = pm4py.read_bpmn(\"Process Models\\Process Model v16.bpmn\")\n",
    "model17 = pm4py.read_bpmn(\"Process Models\\Process Model v17.bpmn\")\n",
    "\n",
    "petri_nets = [\n",
    "    (\"Inductive Miner\", *inductive_model),\n",
    "    (\"Alpha Miner\", *alpha_model),\n",
    "    (\"Heuristic Miner Standard\", *heuristic_model1),\n",
    "    (\"Heuristic Miner Strict\", *heuristic_model2),\n",
    "    (\"Heuristic Miner Balanced\", *heuristic_model3),\n",
    "    (\"Heuristic Miner Noise-tolerant\", *heuristic_model4),\n",
    "    (\"Heuristic Miner Selective\", *heuristic_model5),\n",
    "    (\"v7\",*pm4py.convert_to_petri_net(model7)),\n",
    "    (\"v16\",*pm4py.convert_to_petri_net(model16)),\n",
    "    (\"v17\",*pm4py.convert_to_petri_net(model17))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a9ed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inductive_bpmn_model = pm4py.convert_to_bpmn(*inductive_model)\\nalpha_bpmn_model = pm4py.convert_to_bpmn(*alpha_model)\\nheuristic_bpmn_model1 = pm4py.convert_to_bpmn(*heuristic_model1)\\nheuristic_bpmn_model2 = pm4py.convert_to_bpmn(*heuristic_model2)\\nheuristic_bpmn_model3 = pm4py.convert_to_bpmn(*heuristic_model3)\\nheuristic_bpmn_model4 = pm4py.convert_to_bpmn(*heuristic_model4)\\nheuristic_bpmn_model5 = pm4py.convert_to_bpmn(*heuristic_model5)\\n\\n\\nbpmn_models = [\\n    (\"Inductive Miner\", inductive_bpmn_model),\\n    (\"Alpha Miner\", alpha_bpmn_model),\\n    (\"Heuristic Miner Standard\", heuristic_bpmn_model1),\\n    (\"Heuristic Miner Strict\", heuristic_bpmn_model2),\\n    (\"Heuristic Miner Balanced\", heuristic_bpmn_model3),\\n    (\"Heuristic Miner Noise-tolerant\", heuristic_bpmn_model4),\\n    (\"Heuristic Miner Selective\", heuristic_bpmn_model5),\\n]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"inductive_bpmn_model = pm4py.convert_to_bpmn(*inductive_model)\n",
    "alpha_bpmn_model = pm4py.convert_to_bpmn(*alpha_model)\n",
    "heuristic_bpmn_model1 = pm4py.convert_to_bpmn(*heuristic_model1)\n",
    "heuristic_bpmn_model2 = pm4py.convert_to_bpmn(*heuristic_model2)\n",
    "heuristic_bpmn_model3 = pm4py.convert_to_bpmn(*heuristic_model3)\n",
    "heuristic_bpmn_model4 = pm4py.convert_to_bpmn(*heuristic_model4)\n",
    "heuristic_bpmn_model5 = pm4py.convert_to_bpmn(*heuristic_model5)\n",
    "\n",
    "\n",
    "bpmn_models = [\n",
    "    (\"Inductive Miner\", inductive_bpmn_model),\n",
    "    (\"Alpha Miner\", alpha_bpmn_model),\n",
    "    (\"Heuristic Miner Standard\", heuristic_bpmn_model1),\n",
    "    (\"Heuristic Miner Strict\", heuristic_bpmn_model2),\n",
    "    (\"Heuristic Miner Balanced\", heuristic_bpmn_model3),\n",
    "    (\"Heuristic Miner Noise-tolerant\", heuristic_bpmn_model4),\n",
    "    (\"Heuristic Miner Selective\", heuristic_bpmn_model5),\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdd14d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for name, net, im, fm in petri_nets:\\n    path = name + \" PetriNet.jpg\"\\n    pm4py.save_vis_petri_net(net, im, fm, path)\\n\\nfor name, model in bpmn_models:\\n    path = name + \" BPMN.jpg\"\\n    pm4py.save_vis_bpmn(model,path)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for name, net, im, fm in petri_nets:\n",
    "    path = name + \" PetriNet.jpg\"\n",
    "    pm4py.save_vis_petri_net(net, im, fm, path)\n",
    "\n",
    "for name, model in bpmn_models:\n",
    "    path = name + \" BPMN.jpg\"\n",
    "    pm4py.save_vis_bpmn(model,path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fbbdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg_miner, start_activities, end_activities = pm4py.discover_dfg(log)\n",
    "performance_dfg_miner,start_activities,end_activities = pm4py.discover_performance_dfg(log)\n",
    "pm4py.save_vis_dfg(dfg_miner, start_activities, end_activities, \"DFG.jpg\", format=\"png\")\n",
    "pm4py.save_vis_performance_dfg(performance_dfg_miner,start_activities,end_activities, \"PERF_DFG.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d131bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inductive Miner ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\Desktop\\Repos\\BPPSO - Assignment 1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:51<00:00, 143.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 100.0\n",
      "  average_trace_fitness: 1.0\n",
      "  log_fitness: 1.0\n",
      "  percentage_of_fitting_traces: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [47:06<00:00, 93.37it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.1406587530076867\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.6283\n",
      "  entropy: 0.5955\n",
      "  simplicity_entropy: 0.9076\n",
      "  simplicity_size: 326.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:49<00:00, 145.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9485\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Alpha Miner ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [00:38<00:00, 413.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.40385723651956174\n",
      "  log_fitness: 0.38258984617069436\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [02:28<00:00, 1781.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.09036668421905925\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.5278\n",
      "  entropy: 0.6808\n",
      "  simplicity_entropy: 0.8552\n",
      "  simplicity_size: 93.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [00:38<00:00, 413.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9824\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Heuristic Miner Standard ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:41<00:00, 156.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.9431922134411704\n",
      "  log_fitness: 0.9507858485934311\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [06:53<00:00, 638.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.6710730616980617\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.5187\n",
      "  entropy: 0.7222\n",
      "  simplicity_entropy: 0.8864\n",
      "  simplicity_size: 308.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:41<00:00, 157.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9170\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Heuristic Miner Strict ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:39<00:00, 160.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.9595109630044542\n",
      "  log_fitness: 0.9643053657205476\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [08:56<00:00, 492.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.6317402332453672\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.5184\n",
      "  entropy: 0.7506\n",
      "  simplicity_entropy: 0.8826\n",
      "  simplicity_size: 313.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:40<00:00, 159.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9431\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Heuristic Miner Balanced ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:37<00:00, 163.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.958586567981547\n",
      "  log_fitness: 0.9614295630206435\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [06:49<00:00, 643.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.6716560631911173\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.5128\n",
      "  entropy: 0.7796\n",
      "  simplicity_entropy: 0.8767\n",
      "  simplicity_size: 297.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:36<00:00, 164.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9441\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Heuristic Miner Noise-tolerant ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:43<00:00, 153.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.9431806355812802\n",
      "  log_fitness: 0.9507760750599339\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [06:46<00:00, 649.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.6710730616980617\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.5210\n",
      "  entropy: 0.7170\n",
      "  simplicity_entropy: 0.8869\n",
      "  simplicity_size: 305.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:43<00:00, 153.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9184\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Heuristic Miner Selective ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:36<00:00, 164.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.9599253283931364\n",
      "  log_fitness: 0.9627447651545109\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [06:56<00:00, 633.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.6760333013038569\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.5128\n",
      "  entropy: 0.8102\n",
      "  simplicity_entropy: 0.8722\n",
      "  simplicity_size: 297.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:37<00:00, 163.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9452\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- v7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:08<00:00, 231.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 26.163953156241075\n",
      "  average_trace_fitness: 0.9687952658381422\n",
      "  log_fitness: 0.9716910658926539\n",
      "  percentage_of_fitting_traces: 26.163953156241075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [06:55<00:00, 635.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.535241684446598\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.6538\n",
      "  entropy: 0.5186\n",
      "  simplicity_entropy: 0.9044\n",
      "  simplicity_size: 154.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:08<00:00, 232.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9929\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- v16 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:08<00:00, 230.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.8628885632586348\n",
      "  log_fitness: 0.8836288855728787\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [02:21<00:00, 1860.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.9014254796131032\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.7204\n",
      "  entropy: 0.3444\n",
      "  simplicity_entropy: 0.9348\n",
      "  simplicity_size: 147.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:09<00:00, 229.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9672\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- v17 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:13<00:00, 215.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-based replay fitness:\n",
      "  perc_fit_traces: 0.0\n",
      "  average_trace_fitness: 0.8435209460482853\n",
      "  log_fitness: 0.8734190557292498\n",
      "  percentage_of_fitting_traces: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 263907/263907 [02:27<00:00, 1785.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-based replay precision:\n",
      "  precision: 0.9014254796131032\n",
      "\n",
      "Simplicity:\n",
      "  simplicity_arc_degree: 0.7087\n",
      "  entropy: 0.3376\n",
      "  simplicity_entropy: 0.9378\n",
      "  simplicity_size: 161.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed traces :: 100%|██████████| 15930/15930 [01:13<00:00, 216.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generalization:\n",
      "  generalization: 0.9443\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pm4py\n",
    "import traceback\n",
    "import math\n",
    "from simplicity_metrics import entropy_simplicity_petri_net, size_simplicity_metric\n",
    "\n",
    "for name, net, im, fm in petri_nets:\n",
    "    print(f\"--- {name} ---\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Token-based replay fitness\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        tbr_fitness = pm4py.fitness_token_based_replay(log, net, im, fm)\n",
    "        print(\"Token-based replay fitness:\")\n",
    "        for k, v in tbr_fitness.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing token-based replay fitness:\")\n",
    "        traceback.print_exc()\n",
    "        tbr_fitness = {}\n",
    "\n",
    "    # ----------------------------\n",
    "    # Alignment-based fitness\n",
    "    # ----------------------------\n",
    "    \"\"\"try:\n",
    "        align_fitness = pm4py.fitness_alignments(log, net, im, fm)\n",
    "        print(\"\\nAlignment-based fitness:\")\n",
    "        for k, v in align_fitness.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing alignment-based fitness:\")\n",
    "        traceback.print_exc()\n",
    "        align_fitness = {}\"\"\"\n",
    "    # ----------------------------\n",
    "    # Token-based replay precision\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        tbr_precision = pm4py.precision_token_based_replay(log, net, im, fm)\n",
    "        print(\"\\nToken-based replay precision:\")\n",
    "        print(f\"  precision: {tbr_precision}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing token-based replay precision:\")\n",
    "        traceback.print_exc()\n",
    "        tbr_precision = math.nan\n",
    "\n",
    "    # ----------------------------\n",
    "    # Alignment-based precision\n",
    "    # ----------------------------\n",
    "    \"\"\"try:\n",
    "        align_precision = pm4py.precision_alignments(log, net, im, fm)\n",
    "        print(\"\\nAlignment-based precision:\")\n",
    "        print(f\"  precision: {align_precision}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing alignment-based precision:\")\n",
    "        traceback.print_exc()\n",
    "        align_precision = math.nan\"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # Simplicity metrics\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        simplicity_arc = pm4py.simplicity_petri_net(net, im, fm, variant=\"arc_degree\")\n",
    "    except Exception:\n",
    "        print(\"Error computing arc-degree simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_arc = math.nan\n",
    "\n",
    "    \"\"\"try:\n",
    "        simplicity_cardoso = pm4py.simplicity_petri_net(net, im, fm, variant=\"extended_cardoso\")\n",
    "    except Exception:\n",
    "        print(\"Error computing Cardoso simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_cardoso = math.nan\n",
    "\n",
    "    try:\n",
    "        simplicity_cyclomatic = pm4py.simplicity_petri_net(net, im, fm, variant=\"extended_cyclomatic\")\n",
    "    except Exception:\n",
    "        print(\"Error computing Cyclomatic simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_cyclomatic = math.nan\"\"\"\n",
    "\n",
    "    try:\n",
    "        simplicity_entropy = entropy_simplicity_petri_net(net)\n",
    "    except Exception:\n",
    "        print(\"Error computing entropy-based simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_entropy = {'entropy': math.nan, 'simplicity': math.nan}\n",
    "\n",
    "    try:\n",
    "        simplicity_size = size_simplicity_metric(net)\n",
    "    except Exception:\n",
    "        print(\"Error computing size-based simplicity:\")\n",
    "        traceback.print_exc()\n",
    "        simplicity_size = math.nan\n",
    "\n",
    "    print(\"\\nSimplicity:\")\n",
    "    print(f\"  simplicity_arc_degree: {simplicity_arc:.4f}\" if isinstance(simplicity_arc, (float, int)) else f\"  simplicity_arc_degree: {simplicity_arc}\")\n",
    "    #print(f\"  simplicity_cardoso: {simplicity_cardoso:.4f}\" if isinstance(simplicity_cardoso, (float, int)) else f\"  simplicity_cardoso: {simplicity_cardoso}\")\n",
    "    #print(f\"  simplicity_cyclomatic: {simplicity_cyclomatic:.4f}\" if isinstance(simplicity_cyclomatic, (float, int)) else f\"  simplicity_cyclomatic: {simplicity_cyclomatic}\")\n",
    "    print(f\"  entropy: {simplicity_entropy['entropy']:.4f}\")\n",
    "    print(f\"  simplicity_entropy: {simplicity_entropy['simplicity']:.4f}\")\n",
    "    print(f\"  simplicity_size: {simplicity_size:.4f}\")\n",
    "    \n",
    "\n",
    "    # ----------------------------\n",
    "    # Generalization\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        generalization = pm4py.generalization_tbr(log, net, im, fm)\n",
    "        print(\"\\nGeneralization:\")\n",
    "        print(f\"  generalization: {generalization:.4f}\")\n",
    "    except Exception:\n",
    "        print(\"Error computing generalization:\")\n",
    "        traceback.print_exc()\n",
    "        generalization = math.nan\n",
    "\n",
    "    #print(f\"  weighted_score: {(tbr_fitness['log_fitness'] + tbr_precision['precision'] +0.5*simplicity_arc + 0.5*(1-simplicity_entropy['entropy'])+generalization)/4:.4f}\")\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
